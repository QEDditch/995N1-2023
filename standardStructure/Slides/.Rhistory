knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(ggplot2)
library(tidyverse)
library(tidytext)
my_text <- read_csv("news_articles_example.csv") %>%
select(id, Title)
print(my_text, n = 6)
my_text_uni <- my_text %>%
unnest_tokens(output = word, input = Title)
print(my_text_uni, n = 6)
my_text_bi <- my_text %>%
unnest_tokens(output = bigram, input = Title,
token = "ngrams", n = 2)
print(my_text_bi, n = 6)
my_text_tri <- my_text %>%
unnest_tokens(output = trigram, input = Title,
token = "ngrams", n = 3)
print(my_text_tri, n = 6)
my_text_char <- my_text %>%
unnest_tokens(output = character_shingles, input = Title,
token = "character_shingles", n = 5)
print(my_text_char, n = 6)
my_text_uni_pos <- my_text_uni %>%
left_join(parts_of_speech, by  = "word")
print(my_text_uni_pos, n = 6)
my_text_uni_pos <- my_text_uni_pos %>%
group_by(pos) %>%
count(pos, sort = T)
print(my_text_uni_pos, n = 6)
DT::datatable(my_text_uni_pos,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
print(my_text_uni_count, n = 6)
DT::datatable(my_text_uni_count,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
summarise(my_text_uni_count,
num_words = n(),
mean = mean(n),
sd   = sd(n),
min  = min(n),
max  = max(n))
quantile(my_text_uni_count$n, 0.99)
min_occur <- quantile(my_text_uni_count$n, 0.99)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
g
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(ggplot2)
library(tidyverse)
library(tidytext)
my_text <- read_csv("news_articles_example.csv") %>%
select(id, Title)
print(my_text, n = 6)
my_text_uni <- my_text %>%
unnest_tokens(output = word, input = Title)
print(my_text_uni, n = 6)
my_text_bi <- my_text %>%
unnest_tokens(output = bigram, input = Title,
token = "ngrams", n = 2)
print(my_text_bi, n = 6)
my_text_tri <- my_text %>%
unnest_tokens(output = trigram, input = Title,
token = "ngrams", n = 3)
print(my_text_tri, n = 6)
my_text_char <- my_text %>%
unnest_tokens(output = character_shingles, input = Title,
token = "character_shingles", n = 5)
print(my_text_char, n = 6)
my_text_uni_pos <- my_text_uni %>%
left_join(parts_of_speech, by  = "word")
print(my_text_uni_pos, n = 6)
my_text_uni_pos <- my_text_uni_pos %>%
group_by(pos) %>%
count(pos, sort = T)
print(my_text_uni_pos, n = 6)
DT::datatable(my_text_uni_pos,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
print(my_text_uni_count, n = 6)
DT::datatable(my_text_uni_count,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
summarise(my_text_uni_count,
num_words = n(),
mean = mean(n),
sd   = sd(n),
min  = min(n),
max  = max(n))
min_occur <- quantile(my_text_uni_count$n, 0.99)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
library(plotly)
ggplotly(g)
data(stop_words)
my_text_uni <- my_text_uni %>%
anti_join(stop_words)
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
my_text_uni <- my_text_uni %>%
mutate(word_numeric = as.numeric(word))
DT::datatable(my_text_uni,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni <- my_text_uni %>%
filter(is.na(word_numeric))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
min_occur <- quantile(my_text_uni_count$n, 0.95)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
g
my_text_uni <- my_text_uni %>%
filter(is.na(word_numeric))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
min_occur <- quantile(my_text_uni_count$n, 0.98)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
g
my_stop_words <- tibble(word = c("cop26", "final", "news"),
lexicon = "mywords")
my_text_uni<- my_text_uni %>%
anti_join(my_stop_words)
g <- my_text_uni %>%
count(word, sort = T) %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
g
ggplotly(g)
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(ggplot2)
library(tidyverse)
library(tidytext)
my_text <- read_csv("news_articles_example.csv") %>%
select(id, Title)
print(my_text, n = 6)
my_text_uni <- my_text %>%
unnest_tokens(output = word, input = Title)
print(my_text_uni, n = 6)
my_text_bi <- my_text %>%
unnest_tokens(output = bigram, input = Title,
token = "ngrams", n = 2)
print(my_text_bi, n = 6)
my_text_tri <- my_text %>%
unnest_tokens(output = trigram, input = Title,
token = "ngrams", n = 3)
print(my_text_tri, n = 6)
my_text_char <- my_text %>%
unnest_tokens(output = character_shingles, input = Title,
token = "character_shingles", n = 5)
print(my_text_char, n = 6)
my_text_uni_pos <- my_text_uni %>%
left_join(parts_of_speech, by  = "word")
print(my_text_uni_pos, n = 6)
my_text_uni_pos <- my_text_uni_pos %>%
group_by(pos) %>%
count(pos, sort = T)
print(my_text_uni_pos, n = 6)
DT::datatable(my_text_uni_pos,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
print(my_text_uni_count, n = 6)
DT::datatable(my_text_uni_count,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
summarise(my_text_uni_count,
num_words = n(),
mean = mean(n),
sd   = sd(n),
min  = min(n),
max  = max(n))
min_occur <- quantile(my_text_uni_count$n, 0.99)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
library(plotly)
ggplotly(g)
data(stop_words)
my_text_uni <- my_text_uni %>%
anti_join(stop_words)
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
my_text_uni <- my_text_uni %>%
mutate(word_numeric = as.numeric(word))
DT::datatable(my_text_uni,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni <- my_text_uni %>%
filter(is.na(word_numeric))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
min_occur <- quantile(my_text_uni_count$n, 0.98)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
my_stop_words <- tibble(word = c("cop26", "final", "news"),
lexicon = "mywords")
my_text_uni<- my_text_uni %>%
anti_join(my_stop_words)
g <- my_text_uni %>%
count(word, sort = T) %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
library(ngramr)
library(ggplot2)
googlebook_data  <- ngram(c("science", "technology", "innovation"),
smoothing = 0, year_start = 1900)
g <- ggplot(googlebook_data,
aes(x = Year, y = Frequency, colour=  Phrase)) +
geom_line()
ggplotly(g)
library(textstem)
my_text_uni <- my_text_uni %>%
mutate(word_lemma = textstem::lemmatize_words(word))
DT::datatable(my_text_uni,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word_lemma, sort = T)
min_occur <- quantile(my_text_uni_count$n, 0.99)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word_lemma = reorder(word_lemma, n)) %>%
ggplot(aes(x = word_lemma, y = n, fill = word_lemma)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
g
knitr::opts_chunk$set(echo = FALSE)
library(readr)
library(ggplot2)
library(tidyverse)
library(tidytext)
my_text <- read_csv("news_articles_example.csv") %>%
select(id, Title)
print(my_text, n = 6)
my_text_uni <- my_text %>%
unnest_tokens(output = word, input = Title)
print(my_text_uni, n = 6)
my_text_bi <- my_text %>%
unnest_tokens(output = bigram, input = Title,
token = "ngrams", n = 2)
print(my_text_bi, n = 6)
my_text_tri <- my_text %>%
unnest_tokens(output = trigram, input = Title,
token = "ngrams", n = 3)
print(my_text_tri, n = 6)
my_text_char <- my_text %>%
unnest_tokens(output = character_shingles, input = Title,
token = "character_shingles", n = 5)
print(my_text_char, n = 6)
my_text_uni_pos <- my_text_uni %>%
left_join(parts_of_speech, by  = "word")
print(my_text_uni_pos, n = 6)
my_text_uni_pos <- my_text_uni_pos %>%
group_by(pos) %>%
count(pos, sort = T)
print(my_text_uni_pos, n = 6)
DT::datatable(my_text_uni_pos,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
print(my_text_uni_count, n = 6)
DT::datatable(my_text_uni_count,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
summarise(my_text_uni_count,
num_words = n(),
mean = mean(n),
sd   = sd(n),
min  = min(n),
max  = max(n))
min_occur <- quantile(my_text_uni_count$n, 0.99)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
library(plotly)
ggplotly(g)
data(stop_words)
my_text_uni <- my_text_uni %>%
anti_join(stop_words)
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
my_text_uni <- my_text_uni %>%
mutate(word_numeric = as.numeric(word))
DT::datatable(my_text_uni,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni <- my_text_uni %>%
filter(is.na(word_numeric))
my_text_uni_count <- my_text_uni %>%
count(word, sort = T)
min_occur <- quantile(my_text_uni_count$n, 0.98)
g <- my_text_uni_count %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
my_stop_words <- tibble(word = c("cop26", "final", "news"),
lexicon = "mywords")
my_text_uni<- my_text_uni %>%
anti_join(my_stop_words)
g <- my_text_uni %>%
count(word, sort = T) %>%
filter(n >= min_occur) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(x = word, y = n, fill = word)) +
geom_col() +
theme(legend.position = "none") +
coord_flip()
ggplotly(g)
library(ngramr)
library(ggplot2)
googlebook_data  <- ngram(c("science", "technology", "innovation"),
smoothing = 0, year_start = 1900)
g <- ggplot(googlebook_data,
aes(x = Year, y = Frequency, colour=  Phrase)) +
geom_line()
ggplotly(g)
library(textstem)
my_text_uni <- my_text_uni %>%
mutate(word_lemma = textstem::lemmatize_words(word))
DT::datatable(my_text_uni,
rownames = F,
filter = "top",
class = "hover",
options = list(pageLength = 5))
my_text_uni_count <- my_text_uni %>%
count(word_lemma, sort = T)
my_text_uni_count
my_text_uni_count
my_text_uni_count <- my_text_uni %>%
count(word_lemma, sort = T)
View(my_text_uni_count)
View(my_text)
