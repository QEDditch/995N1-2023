{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from crossref\n",
    "\n",
    "We are going to explore cross_ref which available through an API\n",
    "\n",
    "Read documentation:\n",
    "https://api.crossref.org/swagger-ui/index.html#/Works/get_works\n",
    "\n",
    "Crossref has a specific R package to query the API, which we are going to use today to collect some data\n",
    "Try the code chunck below, but replacing\n",
    "(i) the query for the specific month and year assigned to you in class\n",
    "(ii) increase the limit of the number of paper returned to 400\n",
    "Running these queries take longer since we are waiting a response from a server\n",
    "(iii) Check the first 10 rows in the dataframe\n",
    "(iv) Add your email address to the polite and enter it at the end of query_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyalex pandas requests beautifulsoup4\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_first = \"http://api.crossref.org/works?query=\"\n",
    "query = \"artificial+neural+network\"\n",
    "filter = \"&filter=\"\n",
    "funder = \"has-funder:true,\"\n",
    "from_date = \"from-pub-date:2016-01-01,\"\n",
    "to_date = \"until-pub-date:2016-01-31\"\n",
    "limit = \"&rows=400\"\n",
    "polite = \"&mailto=d.eggleton@sussex.ac.uk\"\n",
    "\n",
    "# Put the query together and call it\n",
    "query_full = api_first + query + filter + funder + from_date + to_date + limit + polite\n",
    "fetch = requests.get(query_full)\n",
    "\n",
    "# Transform the response into a readable component\n",
    "response_content = fetch.content\n",
    "response_text = response_content.decode('utf-8')\n",
    "return_all = json.loads(response_text)\n",
    "\n",
    "# Extract the relevant data and convert it to a DataFrame\n",
    "ANN_data = pd.DataFrame(return_all[\"message\"][\"items\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Check names of the columns available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['indexed', 'reference-count', 'publisher', 'issue', 'funder',\n",
      "       'content-domain', 'accepted', 'abstract', 'DOI', 'type', 'created',\n",
      "       'page', 'source', 'is-referenced-by-count', 'title', 'prefix', 'volume',\n",
      "       'author', 'member', 'published-online', 'reference', 'container-title',\n",
      "       'deposited', 'score', 'resource', 'issued', 'references-count',\n",
      "       'journal-issue', 'URL', 'ISSN', 'issn-type', 'published', 'license',\n",
      "       'short-container-title', 'published-print', 'update-policy', 'language',\n",
      "       'link', 'alternative-id', 'subject', 'assertion', 'article-number',\n",
      "       'event', 'publisher-location', 'posted', 'group-title', 'relation',\n",
      "       'subtype', 'archive', 'published-other', 'editor', 'subtitle',\n",
      "       'original-title', 'institution'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = ANN_data.columns\n",
    "print(column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset from the crossref data collected to look at the top funders within those 400 first data point collected\n",
    "(1) keep only the columns 'container-title', 'DOI', 'title', 'funder'\n",
    "(2) Rename the DOI column to DOI_papers\n",
    "(3) separate funders for each funder taking only one row (using 'unnest' of the purr package in tidyr)\n",
    "(4) View the top 20 rows of the dataframe to see whether things have worked how you intended to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None TÜBİTAK\n"
     ]
    }
   ],
   "source": [
    "# # Select columns and rename\n",
    "ANN_funder = ANN_data[['container-title', 'DOI', 'title', 'funder']]\n",
    "ANN_funder = ANN_funder.rename(columns={'DOI': 'DOI_papers'})\n",
    "\n",
    "#this is a test one\n",
    "first_row_data = ANN_funder.at[0, 'funder']\n",
    "first_dict = first_row_data[0]  # Access the first element in the list\n",
    "doi = first_dict.get('DOI')\n",
    "name = first_dict.get('name')\n",
    "print(doi, name)\n",
    "\n",
    "\n",
    "\n",
    "#ANN_funder = ANN_funder.explode('funder')\n",
    "# Unnest 'funder' column (assuming it contains lists)\n",
    "# # data = ANN_funder.apply(lambda x: pd.Series(json.loads(x['funder'])), axis=1, result_type='expand')\n",
    "# #ANN_funder['test'] = ANN_funder.apply(lambda x: json.loads(x['funder'])['DOI'], axis = 1)\n",
    "# data3 = ANN_funder.explode('funder')\n",
    "# data = data3.to_json()\n",
    "# parsed_data = pd.read_json(data)\n",
    "# print(parsed_data)\n",
    "\n",
    "# Display the first 20 rows\n",
    "#print(df.head(20))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the column names coming from the nested funder dataset:\n",
    "(1) on top of the columns to keep before, keep 'name' and 'DOI_paper'\n",
    "(2) rename 'name' to a more appropriate name (as this is specific to the funder)\n",
    "(3) rename 'DOI' to a more appropriate name (as this is specific to the funder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(row):\n",
    "    if row:  # Check if the row is not empty\n",
    "        first_dict = row[0]  # Access the first element in the list\n",
    "        doi = first_dict.get('DOI')\n",
    "        name = first_dict.get('name')\n",
    "        return doi, name\n",
    "    return None, None\n",
    "\n",
    "\n",
    "ANN_funder['DOI_funder'], ANN_funder['funder_name'] = zip(*ANN_funder['funder'].apply(extract_values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the column names coming from the nested funder dataset:\n",
    "(1) on top of the columns to keep before, keep 'name' and 'DOI_paper'\n",
    "(2) rename 'name' to a more appropriate name (as this is specific to the funder)\n",
    "(3) rename 'DOI' to a more appropriate name (as this is specific to the funder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a summary of the funder data, to identify the top funder in your specific month\n",
    "The resulting dataframe will be arranged in descending order\n",
    "display the top three answers (these will be reported in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      funder_name  count\n",
      "351  National Natural Science Foundation of China    181\n",
      "360         National Research Foundation of Korea     29\n",
      "365                   National Science Foundation     27\n"
     ]
    }
   ],
   "source": [
    "# Group by 'funder_name' and count occurrences, then sort in descending order\n",
    "Funder_summary = ANN_funder.groupby('funder_name').size().reset_index(name='count')\n",
    "Funder_summary = Funder_summary.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Display the top 3 results\n",
    "top_3 = Funder_summary.head(3)\n",
    "print(top_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
